[
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ðŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ðŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "gpt4o Medical Advice: Dogs vs.Â Humans\n\n\n\n\n\n\nMedical Advice\n\n\nHumanity\n\n\n\nJuliaâ€™s first post for comm class\n\n\n\n\n\nJan 29, 2025\n\n\nJulia Levine\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi this is Julia"
  },
  {
    "objectID": "posts/001_med_advice/humansvsdogs.html",
    "href": "posts/001_med_advice/humansvsdogs.html",
    "title": "gpt4o Medical Advice: Dogs vs.Â Humans",
    "section": "",
    "text": "What tone and directive advice does it give when asking about minor injuries for dogs compared to humans?\n\n\n\nScreenshot 2025-02-05 at 2.34.18 PM.png\n\n\nFirst, when asking about medical advice for a minor injury related to the self (human), gpt-4o is quick to appeal to the personâ€™s emotions, then moving to a list of care advice. This list includes injury assessment and various external and internal care actions that are home-based, including long-term care like taping and footwear adjustment. It then closes out with seeking further medical evaluation after a few days of constant pain.\n\n\n\nScreenshot 2025-02-05 at 2.38.40 PM.png\n\n\nComparatively, when asking for the same medical advice, but this time for a dog, gpt-4o takes a less face-to-face approach, instead apologizing for the incident rather than appealing to the dog. The care is also directed towards the humanâ€™s behavior and demeanor, rather than calming the dog down. The medical care for the dog also seems a bit less informed and therefore more severe, such as cleaning the area and monitoring for infection, which the human advice does not really account for. Additionally, included in the list of care is visiting the vet, which gpt-4o only suggests for humans after several days of consistant pain.\nComparative Analysis\nWhen comparing gpt-4oâ€™s responses between human and dog medical advice, gpt-4o seems to take a more human-based approach to both, accurately caring for the human wound, but being a bit less accurate with the dog wound. Both have similar outcomes in terms of visiting a doctor in the event of lasting pain, however the human response addresses this as a last resort, whereas the dog response is more suggestive of immediate vet care, which can be expensive and completely unnecessary."
  },
  {
    "objectID": "posts/001_med_advice/humansvsdogs.html#is-gpt4os-medical-advice-fine-tuned-for-humans",
    "href": "posts/001_med_advice/humansvsdogs.html#is-gpt4os-medical-advice-fine-tuned-for-humans",
    "title": "gpt4o Medical Advice: Dogs vs.Â Humans",
    "section": "",
    "text": "What tone and directive advice does it give when asking about minor injuries for dogs compared to humans?\n\n\n\nScreenshot 2025-02-05 at 2.34.18 PM.png\n\n\nFirst, when asking about medical advice for a minor injury related to the self (human), gpt-4o is quick to appeal to the personâ€™s emotions, then moving to a list of care advice. This list includes injury assessment and various external and internal care actions that are home-based, including long-term care like taping and footwear adjustment. It then closes out with seeking further medical evaluation after a few days of constant pain.\n\n\n\nScreenshot 2025-02-05 at 2.38.40 PM.png\n\n\nComparatively, when asking for the same medical advice, but this time for a dog, gpt-4o takes a less face-to-face approach, instead apologizing for the incident rather than appealing to the dog. The care is also directed towards the humanâ€™s behavior and demeanor, rather than calming the dog down. The medical care for the dog also seems a bit less informed and therefore more severe, such as cleaning the area and monitoring for infection, which the human advice does not really account for. Additionally, included in the list of care is visiting the vet, which gpt-4o only suggests for humans after several days of consistant pain.\nComparative Analysis\nWhen comparing gpt-4oâ€™s responses between human and dog medical advice, gpt-4o seems to take a more human-based approach to both, accurately caring for the human wound, but being a bit less accurate with the dog wound. Both have similar outcomes in terms of visiting a doctor in the event of lasting pain, however the human response addresses this as a last resort, whereas the dog response is more suggestive of immediate vet care, which can be expensive and completely unnecessary."
  }
]